// src/components/ChatRagUI.tsx
"use client";

import React, { useState, useRef, useEffect, useCallback } from "react";
import { motion, AnimatePresence } from "framer-motion";

// ... (ê¸°ì¡´ íƒ€ì… ì„ ì–¸ë“¤ SpeechRecognition, Message, Theme ë“±ì€ ë™ì¼í•˜ê²Œ ìœ ì§€)
type SpeechRecognition = {
  lang: string;
  interimResults: boolean;
  continuous: boolean;
  onstart: () => void;
  onresult: (e: SpeechRecognitionEvent) => void;
  onend: () => void;
  onerror: (e: SpeechRecognitionErrorEvent) => void;
  onnomatch: () => void;
  start(): void;
  stop(): void;
};

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognitionEvent {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

type SpeechRecognitionResultList = {
  [index: number]: SpeechRecognitionResult;
  length: number;
  item: (index: number) => SpeechRecognitionResult;
};

interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative;
  isFinal: boolean;
  length: number;
  item: (index: number) => SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}


declare global {
  interface Window {
    SpeechRecognition: { new (): SpeechRecognition };
    webkitSpeechRecognition: { new (): SpeechRecognition };
    speechSynthesis: SpeechSynthesis; // TTSë¥¼ ìœ„í•œ SpeechSynthesis íƒ€ì… ì¶”ê°€
  }
}

interface Message {
  id: number;
  role: "user" | "assistant";
  content: string;
  originalContent?: string;
  isPlaceholder?: boolean;
  isExpanded?: boolean;
  category?: "ì—°ê¸ˆ" | "ê³ ìš©" | "ë³µì§€" | "ì¼ë°˜";
  isPlaying?: boolean; // TTS ì¬ìƒ ìƒíƒœë¥¼ ìœ„í•œ í•„ë“œ
}

type Theme = "light" | "dark" | "high-contrast";


export default function ChatRagUI() {
  const [fontLevel, setFontLevel] = useState(5);
  const fontScale = fontLevel / 5;
  const [theme, setTheme] = useState<Theme>("light");
  const [listening, setListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  // finalTranscript ìƒíƒœëŠ” ì´ì œ onresultì—ì„œ promptTextë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸í•˜ë¯€ë¡œ, UI í‘œì‹œìš© transcriptë§Œ ìˆì–´ë„ ê´œì°®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  // í•˜ì§€ë§Œ ëª…í™•ì„±ì„ ìœ„í•´ ìœ ì§€í•˜ê±°ë‚˜, í•„ìš” ì—†ë‹¤ë©´ ì œê±°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ìœ ì§€í•˜ê³  onresultì—ì„œ í•¨ê»˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
  const [finalTranscriptForDisplay, setFinalTranscriptForDisplay] = useState("");
  const [promptText, setPromptText] = useState("");
  const recogRef = useRef<SpeechRecognition | null>(null);
  const [messages, setMessages] = useState<Message[]>([]);
  const [viewModes, setViewModes] = useState<Record<number, "simplified" | "original">>({});
  const [expandedStates, setExpandedStates] = useState<Record<number, boolean>>({});
  const [history, setHistory] = useState<string[]>([]);
  const [speechStatus, setSpeechStatus] = useState<string>("");
  const [micError, setMicError] = useState<string>("");

  // TTS ê´€ë ¨ ìƒíƒœ
  const utteranceRef = useRef<SpeechSynthesisUtterance | null>(null);

  const dummyResponses: Omit<Message, "id" | "role">[] = [ /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */ ];
  useEffect(() => { /* ... ê¸°ì¡´ í…Œë§ˆ ë¡œë”© useEffect ... */ }, []);
  useEffect(() => { /* ... ê¸°ì¡´ í…Œë§ˆ ì ìš© useEffect ... */ }, [theme]);

  const toggleListen = () => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) {
      setMicError("ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
      alert("ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
      return;
    }

    if (listening && recogRef.current) {
      recogRef.current.stop();
    } else {
      // TTS ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ì§€
      if (window.speechSynthesis && window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel();
        setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      }

      const recog = new SR() as SpeechRecognition;
      recogRef.current = recog;
      recog.lang = "ko-KR";
      recog.interimResults = true;
      // recog.continuous = false; // í•œ ë²ˆì˜ ë°œí™” í›„ ìë™ ì¢…ë£Œ (ê¸°ë³¸ê°’)

      recog.onstart = () => {
        setListening(true);
        setSpeechStatus("ë“£ê³  ìˆì–´ìš”... ë§ì”€í•´ì£¼ì„¸ìš”.");
        setMicError("");
        setTranscript("");
        setFinalTranscriptForDisplay("");
        setPromptText(""); // ìŒì„± ì…ë ¥ ì‹œì‘ ì‹œ ìµœì¢… ì§ˆë¬¸ ì¹¸ ì´ˆê¸°í™”
      };

      recog.onend = () => {
        setListening(false);
        setSpeechStatus("");
        // promptTextëŠ” onresultì˜ isFinalì—ì„œ ì´ë¯¸ ì„¤ì •ë˜ì—ˆì„ ê²ƒì´ë¯€ë¡œ,
        // ì—¬ê¸°ì„œëŠ” íŠ¹ë³„íˆ promptTextë¥¼ ë‹¤ì‹œ ì„¤ì •í•  í•„ìš”ëŠ” ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        // ë‹¤ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ ì¼€ì´ìŠ¤ë¥¼ ìœ„í•´ ìµœì¢… transcript ê¸°ì¤€ìœ¼ë¡œ í•œë²ˆ ë” ë™ê¸°í™” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        if (finalTranscriptForDisplay.trim() && !promptText.trim()) {
             setPromptText(finalTranscriptForDisplay.trim());
        }
      };

      recog.onresult = (event: SpeechRecognitionEvent) => {
        let interim_transcript = "";
        let final_transcript_piece = "";

        for (let i = event.resultIndex; i < event.results.length; ++i) {
          const transcript_segment = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            final_transcript_piece += transcript_segment;
          } else {
            interim_transcript += transcript_segment;
          }
        }

        // ìµœì¢… í™•ì •ëœ ë¶€ë¶„(final_transcript_piece)ì´ ìˆë‹¤ë©´, promptTextì™€ finalTranscriptForDisplayë¥¼ ì—…ë°ì´íŠ¸
        if (final_transcript_piece) {
          const newFinalText = (finalTranscriptForDisplay + final_transcript_piece).trim();
          setFinalTranscriptForDisplay(newFinalText);
          setPromptText(newFinalText); // << ì¤‘ìš”: ìµœì¢… ì§ˆë¬¸ í•„ë“œ(promptText) ì§ì ‘ ì—…ë°ì´íŠ¸
          setTranscript(newFinalText + " " + interim_transcript); // í™”ë©´ í‘œì‹œìš©ì€ ìµœì¢… + ì¤‘ê°„ ê²°ê³¼
        } else {
          // ì¤‘ê°„ ê²°ê³¼ë§Œ ìˆì„ ê²½ìš°, í™”ë©´ í‘œì‹œìš© transcriptë§Œ ì—…ë°ì´íŠ¸
          setTranscript(finalTranscriptForDisplay + " " + interim_transcript);
        }

        if (interim_transcript) {
            setSpeechStatus("ìŒì„± ì¸ì‹ ì¤‘...");
        }
      };

      recog.onerror = (event: SpeechRecognitionErrorEvent) => { /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */
        console.error("Speech recognition error", event.error, event.message);
        let errorMessage = "ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
        if (event.error === "no-speech") {
          errorMessage = "ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§ˆì´í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.";
        } else if (event.error === "audio-capture") {
          errorMessage = "ë§ˆì´í¬ ì ‘ê·¼ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.";
        } else if (event.error === "not-allowed") {
          errorMessage = "ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.";
        } else if (event.error === "network") {
            errorMessage = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
        }
        setMicError(errorMessage);
        setListening(false);
        setSpeechStatus("");
      };
      recog.onnomatch = () => { /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */
        setSpeechStatus("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?");
      };

      try {
        recog.start();
      } catch (e) { /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */
        console.error("Error starting speech recognition:", e);
        setMicError("ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        setListening(false);
        setSpeechStatus("");
      }
    }
  };

  const handleSend = useCallback(() => {
    const trimmedPrompt = promptText.trim();
    if (!trimmedPrompt) {
      alert("ë¨¼ì € ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ë§í•´ì£¼ì„¸ìš”.");
      return;
    }
    // TTS ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ì§€
    if (window.speechSynthesis && window.speechSynthesis.speaking) {
      window.speechSynthesis.cancel();
      setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
    }

    const userMsg: Message = { id: Date.now(), role: "user", content: trimmedPrompt, category: "ì¼ë°˜" };
    const placeholderMsg: Message = { id: Date.now() + 1, role: "assistant", content: "ìƒê°ì¤‘ì…ë‹ˆë‹¤...", isPlaceholder: true, category: "ì¼ë°˜" };
    setMessages((prev) => [...prev, userMsg, placeholderMsg]);
    setHistory((prevHistory) => [trimmedPrompt, ...prevHistory.filter(h => h !== trimmedPrompt)].slice(0, 3));
    setTranscript("");
    setFinalTranscriptForDisplay("");
    setPromptText("");
    setMicError("");
    setSpeechStatus("");

    setTimeout(() => {
      const randomDummy = dummyResponses[Math.floor(Math.random() * dummyResponses.length)];
      const botMsg: Message = {
        id: Date.now() + 2, role: "assistant", content: randomDummy.content,
        originalContent: randomDummy.originalContent, category: randomDummy.category,
        isExpanded: (randomDummy.content.length <= 100), isPlaying: false
      };
      setViewModes(prev => ({...prev, [botMsg.id]: "simplified"}));
      // setExpandedStatesëŠ” Message isExpanded ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
      setMessages((prev) => [...prev.filter((m) => !m.isPlaceholder), botMsg]);
    }, 2000);
  }, [promptText, dummyResponses]); // dummyResponses ì¶”ê°€

  const examples = [ /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */ ];
  const toggleViewMode = (id: number) => { /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */ };
  const toggleExpand = (id: number) => {
    setMessages(prevMessages => prevMessages.map(msg =>
      msg.id === id ? { ...msg, isExpanded: !msg.isExpanded } : msg
    ));
  };
  const getButtonClass = (isActive: boolean = false) => { /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */ };
  const getInputClass = () => { /* ... ê¸°ì¡´ê³¼ ë™ì¼ ... */ };

  // TTS ì¬ìƒ/ì •ì§€ í•¨ìˆ˜
  const handleSpeak = (message: Message) => {
    if (!window.speechSynthesis) {
      alert("ìŒì„± ì¶œë ¥ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
      return;
    }

    // í˜„ì¬ ë©”ì‹œì§€ê°€ ì´ë¯¸ ì¬ìƒ ì¤‘ì´ë©´ ì·¨ì†Œ
    if (message.isPlaying) {
      window.speechSynthesis.cancel();
      setMessages(prev => prev.map(m => m.id === message.id ? { ...m, isPlaying: false } : m));
      return;
    }

    // ë‹¤ë¥¸ ë©”ì‹œì§€ ì¬ìƒ ì¤‘ì´ë©´ ê·¸ê²ƒë¶€í„° ì·¨ì†Œ ë° ìƒíƒœ ì´ˆê¸°í™”
    if (window.speechSynthesis.speaking) {
      window.speechSynthesis.cancel();
      setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
    }

    const textToSpeak = viewModes[message.id] === 'original' && message.originalContent
                        ? message.originalContent
                        : message.content;

    const utterance = new SpeechSynthesisUtterance(textToSpeak);
    utterance.lang = "ko-KR"; // í•œêµ­ì–´ ì„¤ì •
    utterance.pitch = 1;
    utterance.rate = 1; // ì†ë„ ì¡°ì ˆ ê°€ëŠ¥ (0.1 ~ 10)

    utterance.onstart = () => {
      setMessages(prev => prev.map(m => m.id === message.id ? { ...m, isPlaying: true } : { ...m, isPlaying: false }));
    };
    utterance.onend = () => {
      setMessages(prev => prev.map(m => m.id === message.id ? { ...m, isPlaying: false } : m));
      utteranceRef.current = null;
    };
    utterance.onerror = (event) => {
      console.error("SpeechSynthesis Error", event);
      setMessages(prev => prev.map(m => m.id === message.id ? { ...m, isPlaying: false } : m));
      alert("ìŒì„± ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      utteranceRef.current = null;
    };

    utteranceRef.current = utterance;
    window.speechSynthesis.speak(utterance);
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ TTS ì •ë¦¬
  useEffect(() => {
    return () => {
      if (window.speechSynthesis && window.speechSynthesis.speaking) {
        window.speechSynthesis.cancel();
      }
    };
  }, []);


  return (
    <main /* ... ê¸°ì¡´ main íƒœê·¸ ì†ì„± ... */ >
      {/* ... (ìƒë‹¨ ì»¨íŠ¸ë¡¤ ë°” ê¸°ì¡´ê³¼ ë™ì¼) ... */}
      <div className="absolute top-4 left-1/2 transform -translate-x-1/2 flex space-x-2 z-20 p-2 bg-white/80 dark:bg-gray-800/80 hc:bg-white/80 hc:border hc:border-black backdrop-blur-sm rounded-lg shadow-md">
        <button onClick={() => setFontLevel((l) => Math.max(1, l - 1))} className={getButtonClass(false) + " hc:text-black"} aria-label="ê¸€ì ì‘ê²Œ"> ì‘ê²Œ </button>
        <button onClick={() => setFontLevel(5)} className={getButtonClass(false) + " hc:text-black"} aria-label="ê¸€ì ì›ë˜ëŒ€ë¡œ"> ë³´í†µ </button>
        <button onClick={() => setFontLevel((l) => Math.min(10, l + 1))} className={getButtonClass(false) + " hc:text-black"} aria-label="ê¸€ì í¬ê²Œ"> í¬ê²Œ </button>

        <button onClick={() => setTheme("light")} className={getButtonClass(theme === "light")} aria-label="ë¼ì´íŠ¸ ëª¨ë“œ">â˜€ï¸</button>
        <button onClick={() => setTheme("dark")} className={getButtonClass(theme === "dark")} aria-label="ë‹¤í¬ ëª¨ë“œ">ğŸŒ™</button>
        <button onClick={() => setTheme("high-contrast")} className={getButtonClass(theme === "high-contrast")} aria-label="ê³ ëŒ€ë¹„ ëª¨ë“œ">ğŸ‘ï¸</button>
      </div>

      <motion.div /* ... ê¸°ì¡´ ì™¼ìª½ ì…ë ¥ íŒ¨ë„ ... */ >
        {/* ... (ê¸°ì¡´ ì™¼ìª½ ì…ë ¥ íŒ¨ë„ ë‚´ìš©, speechStatus, micError í‘œì‹œ ë¶€ë¶„ í¬í•¨) ... */}
        <div>
            <h1 className="w-full text-center text-3xl font-bold mb-4 text-gray-800 dark:text-gray-200 hc:text-black">
            ğŸ™ï¸ ë§ë¡œ ë§Œë‚˜ëŠ” ë³µì§€ ë„ìš°ë¯¸
            </h1>
            <div className="space-y-4">
            <div className="flex space-x-2 items-center"> {/* items-center ì¶”ê°€ */}
                <button
                  onClick={toggleListen}
                  aria-label={listening ? "ìŒì„± ì¸ì‹ ì¤‘ì§€" : "ìŒì„± ì¸ì‹ ì‹œì‘"}
                  className={`flex-1 min-h-[52px] py-3 rounded-lg focus:outline-none focus:ring-2 focus:ring-opacity-50 transition-all duration-150 ease-in-out font-semibold relative overflow-hidden
                              ${listening
                                  ? 'bg-red-500 hover:bg-red-600 dark:bg-red-700 dark:hover:bg-red-800 text-white ring-red-400 dark:ring-red-500 hc:bg-red-500 hc:text-white hc:border-black'
                                  : 'bg-blue-600 hover:bg-blue-700 dark:bg-blue-500 dark:hover:bg-blue-600 text-white ring-blue-400 dark:ring-blue-500 hc:bg-blue-600 hc:text-white hc:border-black'
                              }`}
                >
                  {listening && (
                    <motion.div
                      className="absolute inset-0 bg-white opacity-20"
                      animate={{ scale: [1, 1.2, 1], opacity: [0.2, 0.4, 0.2] }}
                      transition={{ duration: 1, repeat: Infinity, ease: "easeInOut" }}
                    />
                  )}
                  {listening ? "â–  ì¤‘ì§€" : "ğŸ¤ ë§í•˜ê¸°"}
                </button>
                <button
                  onClick={() => {
                      setTranscript("");
                      setFinalTranscriptForDisplay("");
                      setPromptText("");
                      setMicError("");
                      setSpeechStatus("");
                      if (listening && recogRef.current) {
                        recogRef.current.stop();
                      }
                  }}
                  className={getButtonClass(false) + ` font-semibold hc:text-black`}
                  aria-label="ì…ë ¥ ë‚´ìš© ì§€ìš°ê¸°"
                >
                  ì§€ìš°ê¸°
                </button>
            </div>

            {(speechStatus || micError) && (
              <div className={`p-2 rounded-md text-sm text-center transition-opacity duration-300
                ${micError ?
                    'bg-red-100 text-red-700 dark:bg-red-800 dark:text-red-200 hc:bg-red-100 hc:text-red-700 hc:border hc:border-red-700' :
                    'bg-blue-50 text-blue-700 dark:bg-blue-900 dark:text-blue-300 hc:bg-blue-50 hc:text-blue-700 hc:border hc:border-blue-700'
                }`}
                role={micError ? "alert" : "status"}
                aria-live={micError ? "assertive" : "polite"}
              >
                {micError || speechStatus}
              </div>
            )}

            <div>
                <label htmlFor="transcriptArea" className="font-medium text-gray-700 dark:text-gray-300 hc:text-black">
                ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸
                </label>
                <textarea
                  id="transcriptArea"
                  rows={3}
                  className={getInputClass()}
                  value={transcript}
                  onChange={(e) => {
                      const newText = e.target.value;
                      setTranscript(newText);
                      setFinalTranscriptForDisplay(newText);
                      setPromptText(newText);
                  }}
                  placeholder={listening && !transcript ? "ë“£ê³  ìˆì–´ìš”..." : "ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤..."}
                  readOnly={listening}
                />
            </div>
            <div>
                <label htmlFor="prompt" className="font-medium text-gray-700 dark:text-gray-300 hc:text-black">
                ğŸ”§ ìµœì¢… ì§ˆë¬¸
                </label>
                <input
                id="prompt"
                type="text"
                className={getInputClass()}
                placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì„¸ìš”."
                value={promptText}
                onChange={(e) => setPromptText(e.target.value)}
                onKeyPress={(e) => e.key === 'Enter' && !e.shiftKey && handleSend()}
                />
            </div>
            <div>
                <label className="font-medium text-gray-700 dark:text-gray-300 hc:text-black">ğŸ’¡ ì˜ˆì‹œ ë¬¸ì¥</label>
                <ul className="space-y-1 mt-1">
                {examples.map((ex) => (
                    <li key={ex}>
                    <button
                        onClick={() => {
                        setPromptText(ex);
                        setTranscript(ex);
                        setFinalTranscriptForDisplay(ex);
                        }}
                        className="w-full text-left p-2 rounded-md hover:bg-gray-100 dark:hover:bg-gray-700 focus:outline-none focus:ring-2 focus:ring-blue-400 dark:focus:ring-blue-500 text-blue-600 dark:text-blue-400 hc:text-blue-600 hc:hover:bg-gray-200 underline"
                    >
                        {ex}
                    </button>
                    </li>
                ))}
                </ul>
            </div>
            {history.length > 0 && ( /* ... ìµœê·¼ ì§ˆë¬¸ UI ... */ )}
            </div>
        </div>
        <button /* ... í™•ì¸&ì „ì†¡ ë²„íŠ¼ ... */ >âœ… í™•ì¸ & ì „ì†¡</button>
      </motion.div>

      <motion.section /* ... ì˜¤ë¥¸ìª½ ì‘ë‹µ íŒ¨ë„ ... */ >
        <AnimatePresence>
          {messages.map((msg) => (
            <motion.article
              key={msg.id}
              /* ... ê¸°ì¡´ article ì†ì„± ... */
              className={`max-w-full lg:max-w-3xl p-4 rounded-xl shadow font-medium relative group ${ /* group í´ë˜ìŠ¤ ì¶”ê°€ */
                msg.role === "user"
                  ? "mr-auto bg-gray-100 dark:bg-gray-700 text-gray-800 dark:text-gray-200 hc:bg-gray-100 hc:text-black hc:border hc:border-gray-400"
                  : "ml-auto bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 hc:bg-blue-100 hc:text-black hc:border hc:border-blue-400"
              }`}
            >
              {/* TTS ë²„íŠ¼ (ì±—ë´‡ ë©”ì‹œì§€ì—ë§Œ í‘œì‹œ) */}
              {msg.role === 'assistant' && !msg.isPlaceholder && window.speechSynthesis && (
                <button
                  onClick={() => handleSpeak(msg)}
                  aria-label={msg.isPlaying ? "ìŒì„± ì¬ìƒ ì¤‘ì§€" : "ë©”ì‹œì§€ ìŒì„±ìœ¼ë¡œ ë“£ê¸°"}
                  title={msg.isPlaying ? "ìŒì„± ì¬ìƒ ì¤‘ì§€" : "ë©”ì‹œì§€ ìŒì„±ìœ¼ë¡œ ë“£ê¸°"}
                  className="absolute top-2 right-2 p-1 rounded-full text-gray-500 dark:text-gray-400 hover:bg-gray-200 dark:hover:bg-gray-700 opacity-0 group-hover:opacity-100 focus:opacity-100 transition-opacity hc:text-black hc:hover:bg-gray-300"
                >
                  {msg.isPlaying ? 'â¹ï¸' : 'ğŸ”Š'}
                </button>
              )}

              {msg.isPlaceholder ? ( /* ... í”Œë ˆì´ìŠ¤í™€ë” ë‚´ìš© ... */ ) : (
                <>
                  <pre className="whitespace-pre-wrap text-left">
                    {msg.role === 'assistant' && viewModes[msg.id] === 'original' && msg.originalContent
                      ? msg.originalContent
                      : msg.content}
                  </pre>
                  {msg.role === 'assistant' && (
                    <div className="mt-2 flex flex-wrap gap-2 items-center"> {/* items-center ì¶”ê°€ */}
                      {/* ... ì›ë¬¸/ì‰¬ìš´ì„¤ëª…, ë”ë³´ê¸°/ê°„ëµíˆ ë²„íŠ¼ ... */}
                       {msg.originalContent && (
                            <button
                                onClick={() => toggleViewMode(msg.id)}
                                className="text-xs px-2 py-1 rounded bg-gray-200 dark:bg-gray-600 hover:bg-gray-300 dark:hover:bg-gray-500 focus:outline-none focus:ring-1 focus:ring-blue-400 hc:bg-gray-300 hc:text-black"
                            >
                                {viewModes[msg.id] === 'simplified' ? 'ì›ë¬¸ ë³´ê¸°' : 'ì‰¬ìš´ ì„¤ëª… ë³´ê¸°'}
                            </button>
                        )}
                        {/* isExpanded ìƒíƒœë¥¼ Message ê°ì²´ì—ì„œ ì§ì ‘ ì‚¬ìš© */}
                        {(msg.content.length > 100 || (msg.originalContent && viewModes[msg.id] === 'original' && msg.originalContent.length > 100)) && (
                            <button
                                onClick={() => toggleExpand(msg.id)}
                                className="text-xs px-2 py-1 rounded bg-gray-200 dark:bg-gray-600 hover:bg-gray-300 dark:hover:bg-gray-500 focus:outline-none focus:ring-1 focus:ring-blue-400 hc:bg-gray-300 hc:text-black"
                            >
                                {msg.isExpanded ? 'ê°„ëµíˆ ë³´ê¸°' : 'ë” ë³´ê¸°'}
                            </button>
                        )}
                    </div>
                  )}
                </>
              )}
            </motion.article>
          ))}
        </AnimatePresence>
        {messages.length === 0 && ( /* ... ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€ ... */ )}
      </motion.section>
    </main>
  );
}